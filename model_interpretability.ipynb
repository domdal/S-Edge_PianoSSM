{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d633fb2",
   "metadata": {},
   "source": [
    "### This notebook shows how to analyze and interpret a trained S-Edge model\n",
    "[Paper-Link](https://link.springer.com/article/10.1007/s10994-025-06807-z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06985fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import torch\n",
    "from src.utils.experimentManager import ExperimentManagerLoadFunction, ExperimentManagerReadExistingEntry\n",
    "from copy import deepcopy\n",
    "\n",
    "# matplotlib graph of the eigenvalues\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 1234\n",
    "# set seed for pytorch and numpy\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "transparent_color_list_plt = [\n",
    "    (31/255, 120/255, 180/255, 0.3),   # Deep Blue\n",
    "    (51/255, 160/255, 44/255, 0.3),    # Forest Green\n",
    "    (227/255, 26/255, 28/255, 0.3),    # Berry Red\n",
    "    (255/255, 127/255, 0/255, 0.3),    # Bright Orange\n",
    "    (106/255, 61/255, 154/255, 0.3),   # Deep Purple\n",
    "    (177/255, 89/255, 40/255, 0.3),    # Sienna Brown\n",
    "    (166/255, 206/255, 227/255, 0.3),  # Sky Blue\n",
    "    (178/255, 223/255, 138/255, 0.3),  # Light Green\n",
    "    (251/255, 154/255, 153/255, 0.3),  # Soft Red\n",
    "    (253/255, 191/255, 111/255, 0.3)   # Apricot Orange\n",
    "]\n",
    "\n",
    "color_list_plt = [\n",
    "    (31/255, 120/255, 180/255),   # Deep Blue\n",
    "    (51/255, 160/255, 44/255),    # Forest Green\n",
    "    (227/255, 26/255, 28/255),    # Berry Red\n",
    "    (255/255, 127/255, 0/255),    # Bright Orange\n",
    "    (106/255, 61/255, 154/255),   # Deep Purple\n",
    "    (177/255, 89/255, 40/255),    # Sienna Brown\n",
    "    (166/255, 206/255, 227/255),  # Sky Blue\n",
    "    (178/255, 223/255, 138/255),  # Light Green\n",
    "    (251/255, 154/255, 153/255),  # Soft Red\n",
    "    (253/255, 191/255, 111/255)   # Apricot Orange\n",
    "]\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 10\n",
    "BIGGER_SIZE = 10\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7ec176",
   "metadata": {},
   "source": [
    "### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d4a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify results path and run number\n",
    "results_path = './results_journal/'\n",
    "run_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cea374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model configuration and paths\n",
    "model_save_path = ExperimentManagerLoadFunction(results_path, run=run_number)\n",
    "model_config = ExperimentManagerReadExistingEntry(model_save_path)\n",
    "\n",
    "# Dynamic import of the model, from backup folder in the model_save_path\n",
    "try:\n",
    "    spec = importlib.util.spec_from_file_location(\"src.model.classifier\", os.path.join(model_save_path, 'backup', 'src', 'model', 'classifier.py'))\n",
    "    print(spec)\n",
    "    ssm_model = importlib.util.module_from_spec(spec)\n",
    "    print(ssm_model)\n",
    "    sys.modules[\"module.name\"] = ssm_model\n",
    "    spec.loader.exec_module(ssm_model)\n",
    "\n",
    "    SC_Model_classifier = ssm_model.SC_Model_classifier\n",
    "except Exception as e:\n",
    "    print(\"Error importing model from backup folder\")\n",
    "    print(e)\n",
    "    print(\"Switing to default model\")\n",
    "    from src.model.classifier import SC_Model_classifier\n",
    "\n",
    "\n",
    "model_init = SC_Model_classifier(input_size=model_config['input_size'],\n",
    "                            classes=model_config['classes'],\n",
    "                            hidden_sizes=model_config['hidden_sizes'],\n",
    "                            output_sizes=model_config['output_sizes'],\n",
    "                            ZeroOrderHoldRegularization=model_config['zeroOrderHoldRegularization'],\n",
    "                            input_bias=model_config['input_bias'],\n",
    "                            bias_init=model_config['bias_init'],\n",
    "                            output_bias=model_config['output_bias'],\n",
    "                            norm=model_config['norm'],\n",
    "                            complex_output=model_config['complex_output'],\n",
    "                            norm_type=model_config['norm_type'],\n",
    "                            B_C_init=model_config['B_C_init'],\n",
    "                            stability=model_config['stability'],\n",
    "                            trainable_SkipLayer=model_config['trainable_skip_connections'],\n",
    "                            act=model_config['act'],\n",
    "                            )\n",
    "# model_trained = SC_Model_classifier(input_size=1, hidden_size=50, output_size=35, n_layer=10, input_bias=True, output_bias=False, complex_output=False, norm=False, norm_type='ln', B_C_init='orthogonal', stability='abs')\n",
    "model_trained = deepcopy(model_init)\n",
    "\n",
    "model_trained.load_state_dict(torch.load(os.path.join(model_save_path, 'best_valid_loss_model.pt'), map_location=torch.device('cpu')),strict=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ff855",
   "metadata": {},
   "source": [
    "### Eigenvalue Analysis\n",
    "\n",
    "##### Continuous Eigenvalues\n",
    "True/Real continuous-time dynamcis as a scaling of the eigenvalues and time scales. (See section 3.3 within the paper)\n",
    "$$\\widetilde{\\lambda}_{r} = \\Delta \\circ \\widetilde{\\lambda}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7189f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison between initialized lamndas and trained lambdas\n",
    "lambdas_init  = [] \n",
    "lambdas_trained = []\n",
    "time_scales_init = []\n",
    "time_scales_trained = []\n",
    "\n",
    "real_dynamics_init = []\n",
    "real_dynamics_trained = []\n",
    "\n",
    "for i in range(len(model_init.seq)):\n",
    "    time_scales_init.append(np.exp(model_init.seq[i].s5.seq.log_step.data.cpu().detach().numpy()))\n",
    "    lambdas = model_init.seq[i].s5.seq.Lambda.data.cpu().detach().numpy()\n",
    "    lambdas_init.append(lambdas)\n",
    "    time_scales_trained.append(np.exp(model_trained.seq[i].s5.seq.log_step.data.cpu().detach().numpy()))\n",
    "    lambdas = model_trained.seq[i].s5.seq.Lambda.data.cpu().detach().numpy()\n",
    "    lambdas[:,0] = -np.abs(lambdas[:,0]) # Ensure real part is negative for stability also done with abs during training\n",
    "    lambdas_trained.append(lambdas)\n",
    "\n",
    "    real_dynamics_init.append(np.expand_dims(time_scales_init[i], 1)*lambdas_init[i])\n",
    "    real_dynamics_trained.append(np.expand_dims(time_scales_trained[i],1)*lambdas_trained[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24508d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the individual eigenvalues \n",
    "fig = go.Figure()\n",
    "for i in range(len(lambdas_init)):\n",
    "    fig.add_trace(go.Scatter(x=lambdas_init[i][:,0], y=lambdas_init[i][:,1], mode='markers', name=f'layer{i}_init'))\n",
    "    fig.add_trace(go.Scatter(x=lambdas_trained[i][:,0], y=lambdas_trained[i][:,1], mode='markers', name=f'layer{i}_trained'))\n",
    "\n",
    "fig.update_xaxes(title='Real part')\n",
    "fig.update_yaxes(title='Imaginary part')\n",
    "fig.update_layout(title='Eigenvalues')\n",
    "fig.show()\n",
    "\n",
    "# plot the eigenvalues scale with time scales -- true/real continuous-time dynamics\n",
    "fig = go.Figure()\n",
    "step_scales = 2**np.arange(0,3)\n",
    "mi = 0\n",
    "for i in range(len(lambdas_init)):\n",
    "    fig.add_trace(go.Scatter(x=real_dynamics_init[i][:,0], y=real_dynamics_init[i][:,1], mode='markers', name=f'layer{i}_init'))\n",
    "    fig.add_trace(go.Scatter(x=real_dynamics_trained[i][:,0], y=real_dynamics_trained[i][:,1], mode='markers', name=f'layer{i}_trained'))\n",
    "    # plot connecting lines\n",
    "    fig.add_trace(go.Scatter(x=[real_dynamics_init[i][0,0],real_dynamics_trained[i][0,0]], y=[real_dynamics_init[i][0,1],real_dynamics_trained[i][0,1]], line=dict(color=\"grey\"), opacity=0.3, mode='lines',legendgroup=f'connection_{i}', name=f'connection_{i}'))\n",
    "    for q in range(len(real_dynamics_init[i][:,0])):\n",
    "        fig.add_trace(go.Scatter(x=[real_dynamics_init[i][q,0],real_dynamics_trained[i][q,0]], y=[real_dynamics_init[i][q,1],real_dynamics_trained[i][q,1]],showlegend=False, line=dict(color=\"grey\"), opacity=0.3,mode='lines',legendgroup=f'connection_{i}', name=f'connection_{i}'))\n",
    "    mi = np.min([mi,np.min(real_dynamics_init[i][:,0])])\n",
    "    mi = np.min([mi,np.min(real_dynamics_trained[i][:,0])])\n",
    "\n",
    "for step_scale in step_scales:\n",
    "    fig.add_vline(x=-3/step_scale, line_dash=\"dash\", line_color=\"black\", line_width=1, opacity=0.3)\n",
    "    fig.add_annotation(x=-3/step_scale, y=0, text=f'1/{step_scale}', showarrow=False, yshift=10, xshift=10, font=dict(size=10))\n",
    "    fig.add_hline(y=(np.pi)/step_scale, line_dash=\"dash\", line_color=\"black\", line_width=1, opacity=0.3)\n",
    "    fig.add_hline(y=-(np.pi)/step_scale, line_dash=\"dash\", line_color=\"black\", line_width=1, opacity=0.3)\n",
    "    fig.add_annotation(x=0, y=(np.pi)/step_scale, text=f'pi/{step_scale}', showarrow=False, yshift=10, xshift=10, font=dict(size=10))\n",
    "    fig.add_annotation(x=0, y=-(np.pi)/step_scale, text=f'-pi/{step_scale}', showarrow=False, yshift=10, xshift=10, font=dict(size=10))\n",
    "\n",
    "# add title and labels\n",
    "fig.update_xaxes(range=[mi*1.2,0])\n",
    "fig.update_xaxes(title='Real part')\n",
    "fig.update_yaxes(title='Imaginary part')\n",
    "fig.update_layout(title='Eigenvalues scaled by time scales -- Real dynamics')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b70d88",
   "metadata": {},
   "source": [
    "#### Discrete eigenvalues\n",
    "$$\\widetilde{\\lambda}_\\mathrm{d} = e^{\\Delta\\circ\\widetilde{\\lambda}\\mathrm{T_s}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec54762",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_scale = 1\n",
    "fig = go.Figure()\n",
    "for i in range(len(lambdas_init)):\n",
    "    discrete_lambdas_init = np.exp((real_dynamics_init[i][:,0]+1j*real_dynamics_init[i][:,1])*step_scale)\n",
    "    discrete_lambdas_trained = np.exp((real_dynamics_trained[i][:,0]+1j*real_dynamics_trained[i][:,1])*step_scale)\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=np.real(discrete_lambdas_init), y=np.imag(discrete_lambdas_init), mode='markers', name=f'layer{i}_init'))\n",
    "    fig.add_trace(go.Scatter(x=np.real(discrete_lambdas_trained), y=np.imag(discrete_lambdas_trained), mode='markers', name=f'layer{i}_trained'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=np.cos(np.linspace(0,2*np.pi,100)), y=np.sin(np.linspace(0,2*np.pi,100)), mode='lines', line=dict(color=\"grey\"), opacity=0.3,showlegend=False))\n",
    "# define squqare size of the plot\n",
    "fig.update_xaxes(range=[-1.2,1.2])\n",
    "fig.update_yaxes(range=[-1.2,1.2])\n",
    "fig.update_xaxes(title='Real part')\n",
    "fig.update_yaxes(title='Imaginary part')\n",
    "fig.update_layout(title='Discrete Eigenvalues scaled by time scales -- Real dynamics')\n",
    "# with and height \n",
    "fig.update_layout(width=600, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707bec92",
   "metadata": {},
   "source": [
    "### Transfer function and Discretization/Aliasign analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7a97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILS\n",
    "def as_complex(t: torch.Tensor, dtype=torch.complex64):\n",
    "    assert t.shape[-1] == 2, \"as_complex can only be done on tensors with shape=(...,2)\"\n",
    "    nt = torch.complex(t[..., 0], t[..., 1])\n",
    "    if nt.dtype != dtype:\n",
    "        nt = nt.type(dtype)\n",
    "    return nt\n",
    "\n",
    "def export_layer_parameters(model_trained, step_scale_list = [1]*10):\n",
    "    layer_dict  = {}\n",
    "    layer_dict_c = {}\n",
    "    for i in range(len(model_trained.seq)):\n",
    "        A_continious = model_trained.seq[i].s5.seq.Lambda.detach()\n",
    "        A_continious[:,0] = -abs(A_continious[:,0])\n",
    "        B_continious = model_trained.seq[i].s5.seq.B.detach()\n",
    "        B_bias_continious = model_trained.seq[i].s5.seq.B_bias.detach()\n",
    "        C = model_trained.seq[i].s5.seq.C.detach()\n",
    "        C_bias = model_trained.seq[i].s5.seq.C_bias.detach()#.numpy()\n",
    "        try:\n",
    "            SkipLayer = model_trained.seq[i].skipLayer.weight.detach().numpy()\n",
    "            #print('real skiplayer:', SkipLayer.shape)\n",
    "        except:\n",
    "            SkipLayer = np.ones((C.shape[0], B_continious.shape[1]))\n",
    "            #print('ones skiplayer:', SkipLayer.shape)\n",
    "        SkipLayer = SkipLayer + 1j * np.zeros_like(SkipLayer) # complex representation with zero imaginary part        \n",
    "\n",
    "        A_continious = as_complex(A_continious)\n",
    "        B_continious = as_complex(B_continious) \n",
    "        B_bias_continious = as_complex(B_bias_continious)\n",
    "        C_continious = as_complex(C).numpy() \n",
    "        C = as_complex(C)\n",
    "        C_bias = as_complex(C_bias)\n",
    "\n",
    "        step_scale = step_scale_list[i]\n",
    "        delta =  torch.exp(model_trained.seq[i].s5.seq.log_step).detach()\n",
    "        #print(delta.shape)\n",
    "        #print(step_scale)\n",
    "        step = step_scale*delta\n",
    "        A_d, Bb_d = model_trained.seq[i].s5.seq.discretize(A_continious, B_continious, B_bias_continious, step, model_trained.seq[i].s5.seq.input_bias)\n",
    "        B_d = Bb_d[:,0:-1]\n",
    "        B_bias_d = Bb_d[:,-1]\n",
    "\n",
    "        layer_dict_c[i] = {f'A': (delta*A_continious).numpy(), f'B': (delta.unsqueeze(1)*B_continious).numpy(), f'B_bias': (delta.unsqueeze(1)*B_bias_continious).numpy(), f'C': C_continious, f'C_bias': C_bias, 'SkipLayer': SkipLayer}\n",
    "        layer_dict[i] = {f'A': A_d.detach().numpy(), f'B': B_d.detach().numpy(), f'B_bias': B_bias_d.detach().numpy(), f'C': C.detach().numpy(), f'C_bias': C_bias.detach().numpy(), 'SkipLayer': SkipLayer, 'step_scale': step_scale}\n",
    "\n",
    "    # Add final Linear Layer\n",
    "    layer_dict[i+1] = {'W': model_trained.decoder.weight.detach().numpy(), 'b': model_trained.decoder.bias.detach().numpy()} \n",
    "    \n",
    "    return layer_dict, layer_dict_c\n",
    "\n",
    "# transfer function of continuous model G(s) = C (sI - A)^-1 B + D(SkipLayer)\n",
    "def transfer_function_Gs(A, B, C, SkipLayer=None, min_freq=-4, Ta_max=1, max_points = 250):\n",
    "    max_freq = np.pi/Ta_max\n",
    "    # Define CUDA tensors for your variables if they aren't already\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    min_freq = torch.tensor(min_freq, device=device)  # Replace min_freq, max_freq with the appropriate values\n",
    "    max_freq = torch.tensor(max_freq, device=device)\n",
    "    max_points = torch.tensor(max_points, device=device)\n",
    "\n",
    "    # map A, B, C SkipLayer to torch tensors\n",
    "    A = torch.tensor(A, device=device)\n",
    "    B = torch.tensor(B, device=device)\n",
    "    C = torch.tensor(C, device=device)\n",
    "\n",
    "    A_conj = torch.conj(A)\n",
    "    B_conj = torch.conj(B)\n",
    "    C_conj = torch.conj(C)\n",
    "\n",
    "    I = torch.eye(A.size(0), device=device)  # Identity matrix of appropriate size\n",
    "    if SkipLayer is not None:\n",
    "        SkipLayer = torch.tensor(SkipLayer, device=device)\n",
    "        SkipLayer_conj = torch.conj(SkipLayer)\n",
    "\n",
    "    # Define the identity matrix I of the same size as A\n",
    "    s = 1j * torch.logspace(min_freq, max_freq, steps=max_points, device=device)  # Complex frequency range  # Frequency range for G(s) (complex frequency s = jω)\n",
    "    #s = 1j *  torch.linspace(0, max_freq, max_points)  # Frequency range for G(s) (complex frequency s = jω)\n",
    "    #s_idx = s.imag <= np.pi/Ta_max\n",
    "    \n",
    "    s_idx = s.imag <= max_freq\n",
    "    s = s[s_idx]\n",
    "\n",
    "    #print('max_freq', max_freq.shape)\n",
    "    #print('s', s.shape)\n",
    "    \n",
    "    if SkipLayer is not None:\n",
    "        # Compute G(s)\n",
    "        G_s = torch.stack([(C @ torch.linalg.inv(si * I - A) @ B + SkipLayer) for si in s])\n",
    "        #print(G_s.shape)\n",
    "        G_s_conj = torch.stack([(C_conj @ torch.linalg.inv(si * I - A_conj) @ B_conj + SkipLayer_conj) for si in s])\n",
    "        #print(G_s_conj.shape)\n",
    "     \n",
    "    else:# Compute the transfer function G(s) at each frequency\n",
    "        G_s = torch.stack([(C @ torch.linalg.inv(si * I - A) @ B ) for si in s])\n",
    "        #print(G_s.shape)\n",
    "        G_s_conj = torch.stack([(C_conj @ torch.linalg.inv(si * I - A_conj) @ B_conj) for si in s])\n",
    "        #print(G_s_conj.shape)\n",
    "\n",
    "    G_s_real = (G_s + G_s_conj) / 2 \n",
    "\n",
    "    G_s_real = G_s_real.detach().cpu().numpy()\n",
    "    s = s.detach().cpu().numpy()\n",
    "\n",
    "    return G_s_real, s\n",
    "\n",
    "# transfer function of discret model G_z = C (zI - A)^-1 B\n",
    "def transfer_function_Gz(A, B, C, s, SkipLayer=None, Ta= 1):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Define the identity matrix I of the same size as A\n",
    "    #s_idx = s.imag <= np.pi/Ta\n",
    "    #s = s[s_idx]\n",
    "\n",
    "    s = torch.tensor(s, device=device)\n",
    "    z = torch.exp(s*Ta)  # Frequency range for G(z) (complex frequency z = exp(jω*Ta)\n",
    "\n",
    "    \n",
    "    # map A, B, C SkipLayer to torch tensors\n",
    "    A = torch.tensor(A, device=device)\n",
    "    B = torch.tensor(B, device=device)\n",
    "    C = torch.tensor(C, device=device)\n",
    "\n",
    "    A_conj = torch.conj(A)\n",
    "    B_conj = torch.conj(B)\n",
    "    C_conj = torch.conj(C)\n",
    "\n",
    "    I = torch.eye(A.size(0), device=device)  # Identity matrix of appropriate size\n",
    "    if SkipLayer is not None:\n",
    "        SkipLayer = torch.tensor(SkipLayer, device=device)\n",
    "        SkipLayer_conj = torch.conj(SkipLayer)\n",
    "\n",
    "    if SkipLayer is not None:\n",
    "        # Compute G(s)\n",
    "        G_z = torch.stack([(C @ torch.linalg.inv(zi * I - A) @ B + SkipLayer) for zi in z])\n",
    "        #print(G_z.shape)\n",
    "        G_z_conj = torch.stack([(C_conj @ torch.linalg.inv(zi * I - A_conj) @ B_conj + SkipLayer_conj) for zi in z])\n",
    "        #print(G_z_conj.shape)\n",
    "     \n",
    "    else:# Compute the transfer function G(s) at each frequency\n",
    "        G_z = torch.stack([(C @ torch.linalg.inv(zi * I - A) @ B ) for zi in z])\n",
    "        #print(G_z.shape)\n",
    "        G_z_conj = torch.stack([(C_conj @ torch.linalg.inv(zi * I - A_conj) @ B_conj) for zi in z])\n",
    "        #print(G_z_conj.shape)\n",
    "\n",
    "    G_z_real = (G_z + G_z_conj) / 2\n",
    "\n",
    "    G_z_real = G_z_real.detach().cpu().numpy()\n",
    "    s = s.detach().cpu().numpy()\n",
    "    z = z.detach().cpu().numpy()\n",
    "\n",
    "    return G_z_real, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ff72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another Visualization of the eigenvalues, Time constants and frequencies.\n",
    "# We link it with the transfer function and discretization/aliasing analysis\n",
    "\n",
    "# Get model parameter dicts\n",
    "layer_dict_d_trained , layer_dict_c_trained = export_layer_parameters(model_trained)\n",
    "layer_dict_d_init , layer_dict_c_init= export_layer_parameters(model_init)\n",
    "\n",
    "scale = 16000 # kHz  sampling rate of the original audio data\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(8.25, 8.25/3))\n",
    "for i in range(len(layer_dict_c_trained)):\n",
    "    A_init = layer_dict_c_init[i]['A']\n",
    "    B_init = layer_dict_c_init[i]['B']\n",
    "    B_bias_init = layer_dict_c_init[i]['B_bias']\n",
    "    C_init = layer_dict_c_init[i]['C']\n",
    "\n",
    "    A_trained = layer_dict_c_trained[i]['A']\n",
    "    B_trained = layer_dict_c_trained[i]['B']\n",
    "    B_bias_trained = layer_dict_c_trained[i]['B_bias']\n",
    "    C_trained = layer_dict_c_trained[i]['C']\n",
    "\n",
    "    ax[i].scatter(A_init.real, A_init.imag, label='Layer '+str(i+1) + ' init', alpha=0.4, color = color_list_plt[0])\n",
    "    ax[i].scatter(A_trained.real, A_trained.imag, label='Layer '+str(i+1) + ' trained', alpha=0.4, color = color_list_plt[i+1])\n",
    "    ax[i].set_xlim([-0.15, 0.01])\n",
    "    ax[i].set_ylim([-1, 1])\n",
    "\n",
    "    ax[i].set_xticks(np.arange(-0.15, 0.01, 0.05))\n",
    "    ax[i].set_yticks(np.arange(-np.pi, np.pi + np.pi/4, np.pi/4))\n",
    "\n",
    "    ax[i].legend()\n",
    "\n",
    "    ax[i].grid(axis='y', linestyle='--')\n",
    "\n",
    "    if i == 1:\n",
    "        ax[i].set_xlabel('Real')\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel('Imaginary')\n",
    "\n",
    "plt.tight_layout()\n",
    "# save figure as pdf\n",
    "plt.savefig(os.path.join(model_save_path, 'eigenvalues.pdf'))\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(8.25, 8.25/3))\n",
    "\n",
    "for i in range(len(layer_dict_c_trained)):\n",
    "    A_init = layer_dict_c_init[i]['A']\n",
    "    B_init = layer_dict_c_init[i]['B']\n",
    "    B_bias_init = layer_dict_c_init[i]['B_bias']\n",
    "    C_init = layer_dict_c_init[i]['C']\n",
    "\n",
    "    A_trained = layer_dict_c_trained[i]['A']\n",
    "    B_trained = layer_dict_c_trained[i]['B']\n",
    "    B_bias_trained = layer_dict_c_trained[i]['B_bias']\n",
    "    C_trained = layer_dict_c_trained[i]['C']\n",
    "\n",
    "    ax[i].scatter(1/(abs(A_init.real)*scale), abs(A_init.imag)*scale/(2*np.pi), alpha=0.5, color = color_list_plt[0], label='Layer '+str(i+1) + ' init')\n",
    "    ax[i].scatter(1/(abs(A_trained.real)*scale), abs(A_trained.imag)*scale/(2*np.pi),  alpha=0.5, color = color_list_plt[i+1], label='Layer '+str(i+1) + ' trained')\n",
    "    ax[i].legend() #loc='upper right'\n",
    "    ax[i].grid()\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_yscale('log')\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_yscale('log')\n",
    "\n",
    "ax[2].set_xscale('log')\n",
    "ax[2].set_yscale('log')\n",
    "#ax.grid()\n",
    "ax[1].set_xlabel('exp. decay time constants [s]')\n",
    "ax[0].set_ylabel('frequencies [Hz]')\n",
    "#ax.legend()\n",
    "plt.tight_layout()\n",
    "# save figure as pdf\n",
    "plt.savefig(os.path.join(model_save_path, 'frequency_time_scales.pdf'))\n",
    "\n",
    "plt.show()\n",
    "# export \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d86e8a",
   "metadata": {},
   "source": [
    "#### Transfer function extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f24f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all transfer functions for all layers, \n",
    "# Warning this can take a while to comput and plot \n",
    "# becasue we have a trasnfer function for each input/output pair for each layer\n",
    "# We plot the G(s) here and just the magnitude\n",
    "fig, ax = plt.subplots(3, 1, figsize=(8.25, 8.25))\n",
    "for layer in range(3):\n",
    "    Ta = 1\n",
    "    T_z = 1\n",
    "    step_scales = [T_z]*10\n",
    "    dictionary_d , dictionary_c = export_layer_parameters(model_trained, step_scale_list = step_scales)\n",
    "\n",
    "    A = np.diag(dictionary_c[layer]['A'])\n",
    "    B = dictionary_c[layer]['B']\n",
    "    C = dictionary_c[layer]['C']\n",
    "    SkipLayer = dictionary_c[layer]['SkipLayer'] \n",
    "    # Including Skip or not is a philosophical question, here we include it, \n",
    "    # becasue we say we analyze the leffects of beeing in the linear pahse of ReLU,\n",
    "    # setting it to none slightly changes the shapes but not drastically\n",
    "\n",
    "    G_s_real, s = transfer_function_Gs(A, B, C, SkipLayer=SkipLayer, Ta_max=Ta)\n",
    "\n",
    "    magnitude = 20*np.log10(np.abs(G_s_real))\n",
    "    phase = np.angle(G_s_real, deg=False)\n",
    "    print('shape mag:', magnitude.shape)\n",
    "    n_out = C.shape[0]\n",
    "    n_in = B.shape[1]\n",
    "    ax[layer].set_xscale('log')\n",
    "    # n_out + n_in random colors for the lines for plotly \n",
    "    color = ['blue', 'red', 'green', 'black', 'orange', 'purple', 'yellow', 'brown', 'pink', 'cyan']\n",
    "    for i_out in range(n_out):\n",
    "        for i_in in range(n_in):\n",
    "            ax[layer].plot(s.imag, magnitude[:,i_out,i_in], label='G(s) Out'+str(i_out) + 'In'+str(i_in), alpha=0.2)#, color=color[layer]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d340de6",
   "metadata": {},
   "source": [
    "##### First Visualization of Discretization Effects\n",
    "Setting the time scales allows to sub-sample the system and introduces aliasign effects.\n",
    "Next graph shows differences between, G(s) and G(z) for the\n",
    "continuous-time and three subsampled-systems for a single input/output transfer function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30770ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of discretization error \n",
    "model = model_trained\n",
    "fig, ax = plt.subplots(2, 1, figsize=(8.25, 8.25/2))\n",
    "layer = 0\n",
    "max_points = 500\n",
    "Ta = 1\n",
    "T_z = 1\n",
    "step_scales = [T_z]*10\n",
    "dictionary_d , dictionary_c = export_layer_parameters(model, step_scale_list = step_scales)\n",
    "A = np.diag(dictionary_c[layer]['A'])\n",
    "B = dictionary_c[layer]['B']\n",
    "C = dictionary_c[layer]['C']\n",
    "SkipLayer = dictionary_c[layer]['SkipLayer']\n",
    "#SkipLayer = None\n",
    "A_d = np.diag(dictionary_d[layer]['A'])\n",
    "B_d = dictionary_d[layer]['B']\n",
    "C_d = dictionary_d[layer]['C']\n",
    "SkipLayer_d = dictionary_d[layer]['SkipLayer']\n",
    "#SkipLayer_d = None\n",
    "G_s_real, s = transfer_function_Gs(A, B, C, SkipLayer=SkipLayer, Ta_max=Ta, max_points= max_points)\n",
    "G_z_real, z = transfer_function_Gz(A_d, B_d, C_d, s, SkipLayer=SkipLayer, Ta=T_z)\n",
    "magnitude = 20*np.log10(np.abs(G_s_real))\n",
    "phase = np.angle(G_s_real, deg=False)\n",
    "magnitude_z = 20*np.log10(np.abs(G_z_real))\n",
    "phase_z = np.angle(G_z_real, deg=False, )\n",
    "\n",
    "\n",
    "T_z = 2\n",
    "step_scales = [T_z]*10\n",
    "dictionary_d , dictionary_c = export_layer_parameters(model, step_scale_list = step_scales)\n",
    "A = np.diag(dictionary_c[layer]['A'])\n",
    "B = dictionary_c[layer]['B']\n",
    "C = dictionary_c[layer]['C']\n",
    "SkipLayer = dictionary_c[layer]['SkipLayer']\n",
    "#SkipLayer = None\n",
    "A_d = np.diag(dictionary_d[layer]['A'])\n",
    "B_d = dictionary_d[layer]['B']\n",
    "C_d = dictionary_d[layer]['C']\n",
    "SkipLayer_d = dictionary_d[layer]['SkipLayer']\n",
    "#SkipLayer_d = None\n",
    "G_s_real, s = transfer_function_Gs(A, B, C, SkipLayer=SkipLayer, Ta_max=Ta,  max_points= max_points)\n",
    "G_z_real, z2 = transfer_function_Gz(A_d, B_d, C_d, s, SkipLayer=SkipLayer, Ta=T_z)\n",
    "magnitude = 20*np.log10(np.abs(G_s_real))\n",
    "phase = np.angle(G_s_real, deg=False)\n",
    "magnitude_z_2 = 20*np.log10(np.abs(G_z_real))\n",
    "\n",
    "T_z = 4\n",
    "step_scales = [T_z]*10\n",
    "dictionary_d , dictionary_c = export_layer_parameters(model, step_scale_list = step_scales)\n",
    "A = np.diag(dictionary_c[layer]['A'])\n",
    "B = dictionary_c[layer]['B']\n",
    "C = dictionary_c[layer]['C']\n",
    "SkipLayer = dictionary_c[layer]['SkipLayer']\n",
    "#SkipLayer = None\n",
    "A_d = np.diag(dictionary_d[layer]['A'])\n",
    "B_d = dictionary_d[layer]['B']\n",
    "C_d = dictionary_d[layer]['C']\n",
    "SkipLayer_d = dictionary_d[layer]['SkipLayer']\n",
    "#SkipLayer_d = None\n",
    "G_s_real, s = transfer_function_Gs(A, B, C, SkipLayer=SkipLayer, Ta_max=Ta,  max_points= max_points)\n",
    "G_z_real, z4 = transfer_function_Gz(A_d, B_d, C_d, s, SkipLayer=SkipLayer, Ta=T_z)\n",
    "magnitude = 20*np.log10(np.abs(G_s_real))\n",
    "phase = np.angle(G_s_real, deg=False)\n",
    "magnitude_z_4 = 20*np.log10(np.abs(G_z_real))\n",
    "\n",
    "\n",
    "print('shape mag:', magnitude.shape)\n",
    "n_out = C_d.shape[0]\n",
    "n_in = B_d.shape[1]\n",
    "\n",
    "i_out=2 # Here you can select the output index you want to plot\n",
    "i_in=0 # Here you can select the input index you want to plot\n",
    "\n",
    "scale = 16000 # kHz  1/s\n",
    "idx_freq_1 = z.imag <= np.pi/1\n",
    "idx_freq_2 = z2.imag <= np.pi/2\n",
    "idx_freq_4 = z4.imag <= np.pi/4\n",
    "\n",
    "error0 = np.abs(magnitude[:,i_out,i_in] - magnitude_z[:,i_out,i_in])\n",
    "error1 = np.abs(magnitude[:,i_out,i_in] - magnitude_z_2[:,i_out,i_in])\n",
    "error2 = np.abs(magnitude[:,i_out,i_in] - magnitude_z_4[:,i_out,i_in])\n",
    "\n",
    "ax[0].plot(s.imag/(2*np.pi)*scale, magnitude[:,i_out,i_in], label='Continuous', alpha=1 , color=color_list_plt[0])\n",
    "\n",
    "ax[0].plot(z[idx_freq_1].imag/(2*np.pi)*scale, magnitude_z[idx_freq_1,i_out,i_in], label='Discrete (T=16kHz)', alpha=1, color=color_list_plt[1])\n",
    "ax[0].plot(z[~idx_freq_1].imag/(2*np.pi)*scale, magnitude_z[~idx_freq_1,i_out,i_in], linestyle='dashdot', alpha=1, color=color_list_plt[1])\n",
    "\n",
    "ax[0].plot(z2[idx_freq_2].imag/(2*np.pi)*scale, magnitude_z_2[idx_freq_2,i_out,i_in], label='Discrete (T=8kHz)', alpha=1, color=color_list_plt[2])\n",
    "ax[0].plot(z2[~idx_freq_2].imag/(2*np.pi)*scale, magnitude_z_2[~idx_freq_2,i_out,i_in], alpha=0.4, color=color_list_plt[2])\n",
    "\n",
    "ax[0].plot(z4[idx_freq_4].imag/(2*np.pi)*scale, magnitude_z_4[idx_freq_4,i_out,i_in], label='Discrete (T=4kHz)', alpha=1, color=color_list_plt[3])\n",
    "ax[0].plot(z4[~idx_freq_4].imag/(2*np.pi)*scale, magnitude_z_4[~idx_freq_4,i_out,i_in],  alpha=0.4, color=color_list_plt[3])\n",
    "\n",
    "ax[0].vlines(scale/2, -60, 25, linestyle='dashdot', alpha=0.7, label='Nyquist (8kHz)',color=color_list_plt[1])\n",
    "ax[0].vlines(scale/4, -60, 25, linestyle='dashed', alpha=0.7, label='Nyquist (4kHz)', color=color_list_plt[2])\n",
    "ax[0].vlines(scale/8, -60, 25, linestyle='dotted', alpha=0.7, label='Nyquist (2kHz)', color=color_list_plt[3])\n",
    "ax[0].set_ylabel('Magnitude [dB]')\n",
    "ax[0].set_ylim([-60, 25])\n",
    "ax[0].set_xlim([0.5, 8500])\n",
    "ax[0].grid()\n",
    "ax[0].legend(ncol=2, loc = 'upper left')\n",
    "ax[0].set_xscale('log')\n",
    "# omit the x labels\n",
    "ax[0].set_xticklabels([])\n",
    "\n",
    "# area plot between zero and error0 \n",
    "ax[1].fill_between(s.imag/(2*np.pi)*scale, 0, error2, alpha=1, label='T=4kHz', color=color_list_plt[3])\n",
    "ax[1].fill_between(s.imag/(2*np.pi)*scale, 0, error2, alpha=0.7, label='T=4kHz', color=color_list_plt[3])\n",
    "\n",
    "ax[1].fill_between(s.imag/(2*np.pi)*scale, 0, error1, alpha=1, label='T=8kHz', color=color_list_plt[2])\n",
    "ax[1].fill_between(s.imag/(2*np.pi)*scale, 0, error1, alpha=1, label='T=8kHz', color=color_list_plt[2])\n",
    "\n",
    "ax[1].fill_between(s.imag/(2*np.pi)*scale, 0, error0, alpha=1, label='T=16kHz', color=color_list_plt[1])\n",
    "\n",
    "\n",
    "#ax[1].plot(s.imag/(2*np.pi)*scale, error0 , label='T=16kHz', alpha=0.9 , color=color_list_plt[1])\n",
    "#ax[1].plot(s.imag/(2*np.pi)*scale, error1 , label='T=8kHz', alpha=0.9 , color=color_list_plt[2])\n",
    "#ax[1].plot(s.imag/(2*np.pi)*scale, error2 , label='T=4kHz', alpha=0.9 , color=color_list_plt[3])\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_ylabel('Discretization Error')\n",
    "ax[1].set_xlabel('Frequency [Hz]')\n",
    "ax[1].set_xlim([0.5, 8500])\n",
    "#ax[1].set_yscale('log')\n",
    "ax[1].grid()\n",
    "ax[1].legend(ncol=3, loc = 'upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "# save figure as pdf\n",
    "plt.savefig(os.path.join(model_save_path, 'transfer_function_element.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af2fdb6",
   "metadata": {},
   "source": [
    "### Discretization Erros per layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92357705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we extract the discretization error as descriped in the paper (See Section A.3)\n",
    "mae_error_list = []\n",
    "rmse_error_list = []\n",
    "mean_relative_error_list = []\n",
    "step_scale_list = []\n",
    "\n",
    "layer_list = []\n",
    "\n",
    "magnitude_z_list = []\n",
    "magnitude_list = []\n",
    "\n",
    "step_scale_sweep = list(np.linspace(1, 64, 64))\n",
    "#step_scale_sweep.extend([2, 4, 8])\n",
    "step_scale_sweep.sort()\n",
    "\n",
    "#step_scale_sweep = np.arange(1, 8.5, 1)\n",
    "Ta_max = step_scale_sweep[-1]\n",
    "\n",
    "for step_scale in tqdm(step_scale_sweep):\n",
    "\n",
    "    Ta = step_scale\n",
    "    step_scales = [step_scale]*6\n",
    "    #print('step_scales', step_scales)\n",
    "    magnitude_z_step_list = []\n",
    "    magnitude_step_list = []\n",
    "    #print(step_scales)\n",
    "    layer_dict_d_trained , layer_dict_c_trained = export_layer_parameters(model_trained, step_scale_list = step_scales)\n",
    "    #layer_dict_d_init , layer_dict_c_init= export_layer_parameters(model_init, step_scale_list=step_scales)\n",
    "  \n",
    "    for i in range(len(layer_dict_c_trained)):\n",
    "    #for i in tqdm(range(3)):\n",
    "        layer = i\n",
    "        layer_list.append(str(layer))\n",
    "        \n",
    "        dictionary_c = layer_dict_c_trained\n",
    "        dictionary_d = layer_dict_d_trained\n",
    "\n",
    "        A = np.diag(dictionary_c[layer]['A'])\n",
    "        B = dictionary_c[layer]['B']\n",
    "        C = dictionary_c[layer]['C']\n",
    "\n",
    "        SkipLayer_c = None #dictionary_c[layer]['SkipLayer']\n",
    "\n",
    "        A_d = np.diag(dictionary_d[layer]['A'])\n",
    "        B_d = dictionary_d[layer]['B']\n",
    "        C_d = dictionary_d[layer]['C']\n",
    "        SkipLayer_d = None #dictionary_d[layer]['SkipLayer']\n",
    "\n",
    "        G_s_real, s = transfer_function_Gs(A , B, C, SkipLayer_c, Ta_max=Ta_max)\n",
    "        G_z_real, z = transfer_function_Gz(A_d , B_d, C_d, s, SkipLayer_d, Ta=Ta)\n",
    "\n",
    "\n",
    "        magnitude = 20*np.log10(np.abs(G_s_real))\n",
    "        magnitude_z = 20*np.log10(np.abs(G_z_real))\n",
    "\n",
    "        magnitude_step_list.append(magnitude)\n",
    "        magnitude_z_step_list.append(magnitude_z)\n",
    "\n",
    "        #print(magnitude.shape)\n",
    "        #print(magnitude_z.shape)\n",
    "\n",
    "        mae_error = np.mean(np.abs(magnitude - magnitude_z))\n",
    "        rmse_error = np.sqrt(np.mean((magnitude - magnitude_z)**2))\n",
    "        mean_relative_error = np.mean(np.abs(magnitude - magnitude_z) / np.abs(magnitude))\n",
    "\n",
    "        mae_error_list.append(mae_error)\n",
    "        rmse_error_list.append(rmse_error)\n",
    "        mean_relative_error_list.append(mean_relative_error)\n",
    "\n",
    "        step_scale_list.append(step_scale)\n",
    "\n",
    "    magnitude_z_list.append(magnitude_z_step_list)\n",
    "    magnitude_list.append(magnitude_step_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors(mag_list):\n",
    "    num_layer = len(mag_list[0])\n",
    "    layer_list = []\n",
    "    step_scale_list = []\n",
    "    mae_error_list = []\n",
    "    length_min = mag_list[-1][layer][:,0,0].shape[0]\n",
    "    for i, step_scale in  enumerate(step_scale_sweep):\n",
    "        #print(step_scale)\n",
    "        max_mag0_lin = np.array(1)\n",
    "        for j in range(num_layer):\n",
    "            #print(j)\n",
    "            length = mag_list[i][j].shape[0]\n",
    "\n",
    "            max_mag0_lin = max_mag0_lin.reshape(1,1,-1)\n",
    "            mag0_lin = 10**(mag_list[0][j][0:length]/20)\n",
    "            mag_lin = 10**(mag_list[i][j][0:length]/20)\n",
    "\n",
    "            mag0_lin = mag0_lin*max_mag0_lin\n",
    "            mag_lin = mag_lin*max_mag0_lin\n",
    "\n",
    "            max_mag0_lin = np.max(np.sum(mag0_lin, axis=2, keepdims=True),axis=0,keepdims=True) # mag0_lin.shape = (freuqency, outdim, indim)\n",
    "\n",
    "            mag0_lin = mag0_lin/max_mag0_lin\n",
    "            mag_lin = mag_lin/max_mag0_lin\n",
    "\n",
    "            error = np.abs(mag_lin - mag0_lin)\n",
    "            mae_error = np.mean(error)\n",
    "\n",
    "            layer_list.append(j)\n",
    "            step_scale_list.append(step_scale)\n",
    "            mae_error_list.append(mae_error)\n",
    "\n",
    "    df = pd.DataFrame({'layer': layer_list, 'step_scale': step_scale_list, 'mae_error': mae_error_list})#, 'rmse_error': rmse_error_list, 'transfer_energy': transfer_energy_list})#, 'base_energy': base_energy_list})\n",
    "\n",
    "    return df\n",
    "\n",
    "df_error = get_errors(magnitude_z_list)\n",
    "\n",
    "df_error.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1961afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(8.25, 8.25/3))\n",
    "\n",
    "for layer in range(df_error['layer'].nunique()):\n",
    "    #df_error_reg_layer = df_error_reg[df_error_reg['layer'] == layer]\n",
    "    df_error_layer = df_error[df_error['layer'] == layer]\n",
    "    #ax[layer].plot(df_error_no_reg_layer['step_scale'], df_error_no_reg_layer['mae_error'], linestyle= '-.', label='Layer '+str(layer+1) + ' unreg.' , color=color_list_plt[layer+1])\n",
    "    ax[layer].plot(df_error_layer['step_scale'], df_error_layer['mae_error'], label='Layer '+str(layer+1) , color=color_list_plt[layer+1])\n",
    "    ax[layer].grid()\n",
    "\n",
    "    ax[layer].set_ylim([1e-7, 1.2])\n",
    "\n",
    "    if layer == 1:\n",
    "        ax[layer].set_xlabel('Downsampling Factor [1]')\n",
    "    if layer == 0:\n",
    "        ax[layer].set_ylabel('discretization error')\n",
    "    ax[layer].legend(loc='upper left')#, bbox_to_anchor=(0, 1))\n",
    "    ax[layer].set_yscale('log')\n",
    "    # specify legend location \n",
    "    #ax[layer].legend(loc='upper right', bbox_to_anchor=(1, 1))\n",
    "#ax.set_xlabel('sampling time [ms]')\n",
    "#ax.set_ylabel('Discritization Error')\n",
    "\n",
    "# save plot as pdf\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(model_save_path, 'discretization_error.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f114f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

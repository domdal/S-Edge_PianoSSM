{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe4a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4461464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.experimentManager import ExperimentManagerLoadFunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de48ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results from the moel trainings\n",
    "# for each folder in the results folder \n",
    "# find all the folders in the results folder\n",
    "results_folder = './results_journal/'\n",
    "config_file_name = 'config.csv'\n",
    "train_hist_file_name = 'train_history.csv'\n",
    "train_sub_epoch_hist_file_name = 'train_sub_epoch_history.csv'\n",
    "test_file_name = 'test_results.csv'\n",
    "folders = [f for f in os.listdir(results_folder) if os.path.isdir(os.path.join(results_folder, f))]\n",
    "\n",
    "hover_data=['hidden_sizes','output_sizes','zeroOrderHoldRegularization','norm','augments','act']\n",
    "# hover_data=['hidden_sizes','output_sizes','zeroOrderHoldRegularization','norm']\n",
    "\n",
    "# add specific columns of the config to the training history\n",
    "keys = ['input_bias', 'complex_output', 'norm', 'bias_init', 'stability']\n",
    "# merge keys to one string\n",
    "merged_key = '/'.join(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(folder,read_sub_epoch_hist=False):\n",
    "    train_hist_all = pd.DataFrame()\n",
    "    for i in range(0,len(folders)):\n",
    "        config_path = os.path.join(results_folder, folders[i], config_file_name)\n",
    "        train_hist_path = os.path.join(results_folder, folders[i], train_hist_file_name)\n",
    "        if folders[i] == 'QUEUE':\n",
    "            continue\n",
    "        # load the config file\n",
    "        config = pd.read_csv(config_path,index_col=0).T\n",
    "        # if bias_init is not in the config file, add it\n",
    "        if 'bias_init' not in config.columns:\n",
    "            config['bias_init'] = 'zero'\n",
    "        # load the training history\n",
    "        if 'stability' not in config.columns:\n",
    "            config['stability'] = 'relu'\n",
    "        try:\n",
    "            train_hist = pd.read_csv(train_hist_path, index_col=0)\n",
    "        except:\n",
    "            print(f'Could not read {train_hist_path}')\n",
    "            continue\n",
    "        # add config to the training history\n",
    "\n",
    "        # add the config to the df\n",
    "        for key in config:\n",
    "            train_hist[key] = config[key].values[0]\n",
    "\n",
    "        \n",
    "\n",
    "        merged_value = '/'.join([str(config[key].values[0]) for key in keys])\n",
    "\n",
    "        train_hist[merged_key] = folders[i].split('_')[0] + '/' + merged_value\n",
    "        train_hist['Run'] = int(folders[i].split('_')[0].split('#')[1])\n",
    "\n",
    "        train_hist_all = pd.concat([train_hist_all, train_hist], ignore_index=True)\n",
    "        \n",
    "        # # read sub epoch history\n",
    "        if read_sub_epoch_hist:\n",
    "            if os.path.exists(os.path.join(results_folder, folders[i], train_sub_epoch_hist_file_name)):\n",
    "                sub_history = pd.read_csv(os.path.join(results_folder, folders[i], train_sub_epoch_hist_file_name))\n",
    "                sub_history['Run'] = int(folders[i].split('_')[0].split('#')[1])\n",
    "                train_hist_all = pd.concat([train_hist_all, sub_history], ignore_index=True)\n",
    "                if 'lr' in sub_history.columns:\n",
    "                    sub_history['lr'] = sub_history['lr'].astype(float)\n",
    "                print(\"Read sub history\")\n",
    "    return train_hist_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fddb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(folders):\n",
    "    test_all = pd.DataFrame()\n",
    "    for i in range(0,len(folders)):\n",
    "        config_path = os.path.join(results_folder, folders[i], config_file_name)\n",
    "        train_hist_path = os.path.join(results_folder, folders[i], test_file_name)\n",
    "        if folders[i] == 'QUEUE':\n",
    "            continue\n",
    "        # load the config file\n",
    "        config = pd.read_csv(config_path,index_col=0).T\n",
    "        # if bias_init is not in the config file, add it\n",
    "        if 'bias_init' not in config.columns:\n",
    "            config['bias_init'] = 'zero'\n",
    "        # load the training history\n",
    "        if 'stability' not in config.columns:\n",
    "            config['stability'] = 'relu'\n",
    "        try:\n",
    "            test = pd.read_csv(train_hist_path, index_col=0)\n",
    "            \n",
    "        except:\n",
    "            print(f'Could not read {train_hist_path}')\n",
    "            continue\n",
    "\n",
    "        # add the config to the df\n",
    "        for key in config:\n",
    "            test[key] = config[key].values[0]\n",
    "\n",
    "        test['Run'] = int(folders[i].split('_')[0].split('#')[1])\n",
    "        # add config to the training history\n",
    "        merged_value = '/'.join([str(config[key].values[0]) for key in keys])\n",
    "\n",
    "        test[merged_key] = merged_value\n",
    "\n",
    "        test_all = pd.concat([test_all, test])\n",
    "    return test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45507d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist_all = load_train(folders,read_sub_epoch_hist=False)\n",
    "test_all = load_test(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1124b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist_all['epoch'] = train_hist_all['epoch'].astype(float)\n",
    "train_hist_all.sort_values(by=['epoch','Run'], inplace=True)\n",
    "train_hist_all.reset_index(drop=True, inplace=True)\n",
    "train_hist_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54126a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all.sort_values(by=['Run'], inplace=True)\n",
    "test_all.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # test_all.sort_values(by=['test_acc'], ascending=False ,inplace=True)\n",
    "# # test_all.sort_values(by=['test_acc_8k'], ascending=False ,inplace=True)\n",
    "# # test_all.sort_values(by=['test_acc_4k'], ascending=False ,inplace=True)\n",
    "test_all.sort_values(by=['params','test_acc','output_sizes'], ascending=[False,False,False] ,inplace=True)\n",
    "# test_all.sort_values(by=['best_val_acc'], ascending=[False] ,inplace=True)\n",
    "\n",
    "# test_all = test_all.query('zeroOrderHoldRegularization==\"[]\" and norm==\"True\" and B_C_init==\"S5\"')\n",
    "# test_all = test_all.query('norm==\"False\"')\n",
    "# test_all = test_all.query('dropout==\"0.0\"')\n",
    "# slice = test_all.query(' hidden_sizes==\"[32, 16, 8]\" ')\n",
    "for params in test_all['params'].unique():\n",
    "    slice = test_all.query('params==@params')\n",
    "    # print(f\"{slice[['Run','params','zeroOrderHoldRegularization','test_acc_16k','best_val_acc_epoch','test_acc','best_val_acc','test_acc_8k','test_acc_4k','output_sizes','hidden_sizes','augments','lr','weight_decay','norm', 'dropout','norm', 'B_C_init']].to_string()}\")\n",
    "    print(f\"{slice[['Run','params','zeroOrderHoldRegularization','best_val_acc_epoch','test_acc','best_val_acc','output_sizes','hidden_sizes','augments','lr','weight_decay','norm', 'dropout','norm', 'B_C_init']].to_string()}\")\n",
    "    print(\"\")\n",
    "# slice = test_all.query('params==61285')\n",
    "# # slice = test_all\n",
    "# print(f\"{slice[['Run','params','zeroOrderHoldRegularization','test_acc_16k','test_acc','best_val_acc','test_acc_8k','test_acc_4k','output_sizes','hidden_sizes','augments','lr','weight_decay','norm', 'dropout', 'B_C_init']].to_string()}\")\n",
    "# # print(test_all.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf5875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the training history\n",
    "display_list = ['test_acc_16k', 'test_acc_8k', 'test_acc_4k', 'test_acc', 'best_val_acc']\n",
    "for display in display_list:\n",
    "    # fig =  px.line(test_all, x='params', y=display, color='Run',hover_name=merged_key, hover_data=hover_data, markers='.')\n",
    "    test_all['group'] = test_all['output_sizes'].apply(lambda x: str(x).split('[')[-1].split(',')[0])\n",
    "    fig =  px.box(test_all, x='params', y=display,hover_name=merged_key, hover_data=hover_data,points=\"all\", color='group')\n",
    "    fig.update_layout(\n",
    "        xaxis_title='Number of Parameters',\n",
    "        yaxis_title=display,\n",
    "        title=f'Test Accuracy {display}'\n",
    "    )\n",
    "    fig.update_traces(width=2000)\n",
    "\n",
    "    # fig.update_traces(showlegend=False)\n",
    "\n",
    "    fig2 = go.Figure()\n",
    "\n",
    "\n",
    "    group = test_all.groupby(['params','dropout'])\n",
    "    group = group[display].mean().reset_index()\n",
    "    group['params'] = group['params'].astype(float)\n",
    "    group['dropout'] = group['dropout'].astype(float)\n",
    "\n",
    "    slice1 = group[group['dropout']==0]\n",
    "    fig.add_trace(go.Scatter(x=slice1['params'], y=slice1[display], mode='lines', name='Mean dropout 0.0',line=dict(dash='dot')))\n",
    "    slice2 = group[group['dropout']==0.1]\n",
    "    fig.add_trace(go.Scatter(x=slice2['params'], y=slice2[display], mode='lines', name='Mean dropout 0.1',line=dict(dash='dot')))\n",
    "\n",
    "    slice1 = slice1.copy()\n",
    "    slice2 = slice2.copy()\n",
    "\n",
    "    slice1.sort_values(by='params', inplace=True,ignore_index=True)\n",
    "    slice2.sort_values(by='params', inplace=True,ignore_index=True)\n",
    "\n",
    "    fig2.add_trace(go.Bar(x=slice1['params'], y=slice2[display]-slice1[display], name='Enabling Dropout'))\n",
    "\n",
    "    group = test_all.groupby(['params','zeroOrderHoldRegularization'])\n",
    "    group = group[display].mean().reset_index()\n",
    "    group['params'] = group['params'].astype(float)\n",
    "\n",
    "    slice1 = group[group['zeroOrderHoldRegularization']=='[]']\n",
    "    fig.add_trace(go.Scatter(x=slice1['params'], y=slice1[display], mode='lines', name='Mean zeroOrderHoldRegularization []',line=dict(dash='dash')))\n",
    "    slice2 = group[group['zeroOrderHoldRegularization']!='[]']\n",
    "    fig.add_trace(go.Scatter(x=slice2['params'], y=slice2[display], mode='lines', name='Mean zeroOrderHoldRegularization not []',line=dict(dash='dash')))\n",
    "\n",
    "    slice1 = slice1.copy()\n",
    "    slice2 = slice2.copy()\n",
    "\n",
    "    slice1.sort_values(by='params', inplace=True,ignore_index=True)\n",
    "    slice2.sort_values(by='params', inplace=True,ignore_index=True)\n",
    "\n",
    "    fig2.add_trace(go.Bar(x=slice1['params'], y=slice2[display]-slice1[display], name='Enabling ZeroOrderHoldRegularization'))\n",
    "\n",
    "    group = test_all.groupby(['params','norm'])\n",
    "    group = group[display].mean().reset_index()\n",
    "    group['params'] = group['params'].astype(float)\n",
    "\n",
    "    slice1 = group[group['norm']==\"False\"]\n",
    "    fig.add_trace(go.Scatter(x=slice1['params'], y=slice1[display], mode='lines', name='Mean norm False',line=dict(dash='dashdot')))\n",
    "    slice2 = group[group['norm']==\"True\"]\n",
    "    fig.add_trace(go.Scatter(x=slice2['params'], y=slice2[display], mode='lines', name='Mean norm True',line=dict(dash='dashdot')))\n",
    "\n",
    "    slice1 = slice1.copy()\n",
    "    slice2 = slice2.copy()\n",
    "\n",
    "    slice1.sort_values(by='params', inplace=True,ignore_index=True)\n",
    "    slice2.sort_values(by='params', inplace=True,ignore_index=True)\n",
    "\n",
    "    fig2.add_trace(go.Bar(x=slice1['params'], y=slice2[display]-slice1[display], name='Enabling Norm'))\n",
    "    \n",
    "\n",
    "\n",
    "    fig.show()\n",
    "    fig.write_html(f\"{display}_over_runs.html\")\n",
    "\n",
    "\n",
    "    fig2.update_layout(\n",
    "        xaxis_title='Number of Parameters',\n",
    "        yaxis_title=display,\n",
    "        title=f'Test Accuracy mean difference {display}'\n",
    "    )\n",
    "    fig2.update_traces(showlegend=True)\n",
    "    fig2.show()\n",
    "    fig2.write_html(f\"{display}_over_runs_mean_diff.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1344390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training history\n",
    "fig = px.line(train_hist_all, x='epoch', y='train_acc', color='Run',hover_name=merged_key, hover_data=hover_data, markers='.', title='Train Accuracy')\n",
    "# fig.update_yaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f0f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training history\n",
    "fig = px.line(train_hist_all, x='epoch', y='train_loss', color='Run',hover_name=merged_key, hover_data=hover_data,markers='.', title='Train Loss')\n",
    "fig.update_yaxes(type=\"log\") \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training history\n",
    "fig = px.line(train_hist_all, x='epoch', y='valid_acc', color='Run',hover_name=merged_key, hover_data=hover_data,markers='.', title='Valid Accuracy')\n",
    "fig.update_yaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c1b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training history\n",
    "fig = px.line(train_hist_all, x='epoch', y='valid_loss', color='Run',hover_name=merged_key,  hover_data=hover_data, markers='.', title='Valid Loss', log_y=True)\n",
    "fig.update_yaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ae8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training history\n",
    "fig = px.line(train_hist_all, x='epoch', y='lr', color='Run',hover_name=merged_key,markers='.', title='Learning rate')\n",
    "fig.update_yaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9df04e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  training history\n",
    "fig = px.line(train_hist_all, x='epoch', y='learning_rate', color='Run',hover_name=merged_key,markers='.', title='Learning rate')\n",
    "fig.update_yaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc63ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths = []\n",
    "# 8 k Param\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=106))\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=107)) # reg\n",
    "\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=88))\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=89)) # reg\n",
    "\n",
    "\n",
    "# 20k param\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=194))\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=195)) # reg\n",
    "\n",
    "# # others\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=410)) # 20k S5\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=388)) # 56k S5\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=389)) # 56k S5 reg\n",
    "\n",
    "\n",
    "\n",
    "###### TOP Accuracy Runs !!! ###############\n",
    "# 8 k Param BN=True\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=304))\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=305)) # reg\n",
    "\n",
    "# # 20k param BN=True\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=302))\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=303)) # reg\n",
    "\n",
    "\n",
    "# # 56k param BN = True\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=298))\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=299)) # reg\n",
    "\n",
    "# 141k param\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=144))\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=145)) # reg\n",
    "\n",
    "# paths.append(ExperimentManagerLoadFunction(results_folder,run=11)) \n",
    "\n",
    "paths.append(ExperimentManagerLoadFunction(results_folder,run=0))\n",
    "\n",
    "\n",
    "# \n",
    "device_frequencies = {'L4R5ZIT6U':120e6,'F303K8':72e6,}\n",
    "cycles_per_mac = 6 # das könnte möglicherweise erreichbar sein mit allen weights im ram\n",
    "sampling_rate = 16e3\n",
    "\n",
    "fig2 = go.Figure()\n",
    "\n",
    "x_axis = 'macs percent'\n",
    "# x_axis = 'macs'\n",
    "\n",
    "for path in paths:\n",
    "    print(path)\n",
    "    run = int(path.split('/')[-1].split('_')[0].split('#')[1])\n",
    "    df = []\n",
    "    for files in os.listdir(path):\n",
    "        if 'test_results_flops_step_scale' in files:\n",
    "            df.append(pd.read_csv(os.path.join(path,files),sep=','))\n",
    "    df = pd.concat(df)\n",
    "\n",
    "    # read and add config file\n",
    "    config = pd.read_csv(os.path.join(path, config_file_name), index_col=0).T\n",
    "    for key in config:\n",
    "        df[key] = config[key].values[0]\n",
    "\n",
    "    #plot with plotly\n",
    "    # fig = go.Figure()\n",
    "    fig = px.scatter(df, y='test_acc', x=x_axis, color='step_scale', hover_data=['macs',x_axis,'params',*hover_data], title=path)\n",
    "    fig.update_traces(showlegend=False)\n",
    "\n",
    "    pareto_front = df.sort_values(by='test_acc', ascending=False).drop_duplicates(subset=['step_scale'])\n",
    "    pareto_front = pareto_front.cummin(0)\n",
    "    # filter the pareto points\n",
    "    pareto_front2 = df.sort_values(by='test_acc', ascending=False).drop_duplicates(subset=['step_scale'])\n",
    "    pareto_front2 = pareto_front2[pareto_front2[x_axis]==pareto_front[x_axis]]\n",
    "    fig.add_trace(go.Scatter(x=pareto_front2[x_axis], y=pareto_front2['test_acc'], mode='lines', line=dict(color='gray', dash='dash'), name='Pareto Front'))\n",
    "    tmp = px.scatter(pareto_front2, y='test_acc', x=x_axis, hover_data=['step_scale','macs','macs percent','params',*hover_data], title=path)\n",
    "    # tmp.data[0]['name'] = 'Pareto Points'\n",
    "    # tmp.update_traces(name='Pareto Points')\n",
    "    fig.add_trace(tmp.data[0])\n",
    "    fig.data[-1]['name'] = 'Pareto Points'\n",
    "    fig.data[-1]['showlegend'] = True\n",
    "\n",
    "\n",
    "\n",
    "    fig2.add_trace(go.Scatter(x=pareto_front2[x_axis], y=pareto_front2['test_acc'], mode='lines', name=f'Run {run}'))\n",
    "\n",
    "    # the [n,X,X] pareto fronts\n",
    "    for n in range(1,10+1):\n",
    "        slice = df[df['step_scale'].str.contains(f'[{n},',regex=False)]\n",
    "        if slice.empty:\n",
    "            continue\n",
    "        pareto_front = slice.sort_values(by='test_acc', ascending=False).drop_duplicates(subset=['step_scale'])\n",
    "        pareto_front = pareto_front.cummin(0)\n",
    "        pareto_front2 = slice.sort_values(by='test_acc', ascending=False).drop_duplicates(subset=['step_scale'])\n",
    "        pareto_front2 = pareto_front2[pareto_front2[x_axis]==pareto_front[x_axis]]\n",
    "        # pareto_front2 = pareto_front\n",
    "        fig.add_trace(go.Scatter(x=pareto_front2[x_axis], y=pareto_front2['test_acc'], mode='lines', line=dict(dash='dot'), name=f'Pareto Front [{n},X,...,X]'))\n",
    "\n",
    "\n",
    "    # add the second sweep\n",
    "    # plot a horizontal line for the best accuracy scatter dasehd black line\n",
    "    # fig.add_hline(y=0.9251249, line=dict(color='gray', dash='dash'))\n",
    "    # for name,device_frequency in device_frequencies.items():\n",
    "    #     fig.add_vline(x=(device_frequency/sampling_rate)/cycles_per_mac, line=dict(color='gray', dash='dash'))\n",
    "    #     fig.add_annotation(x=(device_frequency/sampling_rate)/cycles_per_mac, y=0.9251249, text=f'{name}', showarrow=True, arrowhead=1)\n",
    "\n",
    "    #fig.add_trace(go.Scatter(x=[30, 110], y=[0.8752, 0.8752], mode='lines', line=dict(color='gray', dash='dash')))\n",
    "    #fig.add_trace(go.Scatter(x=[30, 110], y=[0.736, 0.736], mode='lines', line=dict(color='gray', dash='dash')))\n",
    "    # change x-axis name \n",
    "    # fig.update_xaxes(title='MACs')\n",
    "    # set y-axis to log scale\n",
    "    fig.update_yaxes(title='Test Accuracy')\n",
    "    # fig.update_yaxes(type='log')\n",
    "    fig.update_layout(title=f'Test Accuracy vs MACs {path}')\n",
    "    # fig.update_yaxes(range=[0.92,0.95])\n",
    "    if x_axis == 'macs percent':\n",
    "        fig.update_xaxes(title='MACs [%]')\n",
    "        fig.update_xaxes(range=[0,100])\n",
    "\n",
    "    # fig.update_xaxes(type='log')\n",
    "    # fig.update_xaxes(range=[0,2])\n",
    "    fig.update_xaxes(title='MACs [%]')\n",
    "\n",
    "    fig.show()\n",
    "    fig.write_html(f\"{path.split('/')[-1]}.html\")\n",
    "    # del fig\n",
    "# fig2.add_hline(y=0.9251249, line=dict(color='gray', dash='dash'))\n",
    "# for name,device_frequency in device_frequencies.items():\n",
    "#     fig2.add_vline(x=(device_frequency/sampling_rate)/cycles_per_mac, line=dict(color='gray', dash='dash'))\n",
    "#     fig2.add_annotation(x=(device_frequency/sampling_rate)/cycles_per_mac, y=0.9251249, text=f'{name}', showarrow=True, arrowhead=1)\n",
    "\n",
    "fig2.update_xaxes(title='MACs [%]')\n",
    "fig2.update_yaxes(title='Test Accuracy')\n",
    "fig2.update_layout(title=f'Pareto fronts for Test Accuracy vs MACs')\n",
    "# fig2.update_yaxes(type='log')\n",
    "# fig2.update_xaxes(type='log')\n",
    "# fig2.update_xaxes(type='log', range=[0,2])\n",
    "if x_axis == 'macs percent':\n",
    "    fig2.update_xaxes(title='MACs [%]')\n",
    "    # fig.update_xaxes(range=[0,2])\n",
    "    fig2.update_xaxes(range=[0,100])\n",
    "fig2.show()\n",
    "\n",
    "# fig2.write_html(f\"pareto_fronts.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
